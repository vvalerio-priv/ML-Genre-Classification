{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/valerio/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#\n",
    "# import requirements\n",
    "#\n",
    "########################################################\n",
    "import logging\n",
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtraction:\n",
    "\n",
    "    \"Music audio features for genre classification\"\n",
    "    hop_length = None\n",
    "    genre_list = [\n",
    "        \"blues\",\n",
    "        \"classical\",\n",
    "        \"country\",\n",
    "        \"disco\",\n",
    "        \"hiphop\",\n",
    "        \"jazz\",\n",
    "        \"metal\",\n",
    "        \"pop\",\n",
    "        \"reggae\",\n",
    "        \"rock\",\n",
    "        \"bamileke\",\n",
    "        \"bikutsi\",\n",
    "        \"makossa\",\n",
    "        \"salsa\",\n",
    "        \"zouk\"\n",
    "    ]\n",
    "\n",
    "    #ORIGINAL GTZAN AUDIO SAMPLES\n",
    "    dir_blues = \"./gtzan/gtzan+/gtzan/blues\"\n",
    "    dir_classical = \"./gtzan/gtzan+/gtzan/classical\"\n",
    "    dir_country = \"./gtzan/gtzan+/gtzan/country\"\n",
    "    dir_disco = \"./gtzan/gtzan+/gtzan/disco\"\n",
    "    dir_hiphop = \"./gtzan/gtzan+/gtzan/hiphop\"\n",
    "    dir_jazz = \"./gtzan/gtzan+/gtzan/jazz\"\n",
    "    dir_metal = \"./gtzan/gtzan+/gtzan/metal\"\n",
    "    dir_pop = \"./gtzan/gtzan+/gtzan/pop\"\n",
    "    dir_reggae = \"./gtzan/gtzan+/gtzan/reggae\"\n",
    "    dir_rock = \"./gtzan/gtzan+/gtzan/rock\"\n",
    "\n",
    "    #AFRO EXTENDED GTZAN AUDIO SAMPLES\n",
    "    dir_bamileke = \"./gtzan/gtzan+/afro/bamileke\"\n",
    "    dir_bikutsi = \"./gtzan/gtzan+/afro/bikutsi\"\n",
    "    dir_makossa = \"./gtzan/gtzan+/afro/makossa\"\n",
    "    dir_salsa = \"./gtzan/gtzan+/afro/salsa\"\n",
    "    dir_zouk = \"./gtzan/gtzan+/afro/zouk\"\n",
    "\n",
    "\n",
    "\n",
    "    #dir_trainfolder = \"./gtzan/_train\"\n",
    "    #dir_devfolder = \"./gtzan/_validation\"\n",
    "    #dir_testfolder = \"./gtzan/_test\"\n",
    "    #dir_all_files = \"./gtzan\"\n",
    "\n",
    "    train_X_preprocessed_data = \"./gtzan/data_train_input.npy\"\n",
    "    train_Y_preprocessed_data = \"./gtzan/data_train_target.npy\"\n",
    "    dev_X_preprocessed_data = \"./gtzan/data_validation_input.npy\"\n",
    "    dev_Y_preprocessed_data = \"./gtzan/data_validation_target.npy\"\n",
    "    test_X_preprocessed_data = \"./gtzan/data_test_input.npy\"\n",
    "    test_Y_preprocessed_data = \"./gtzan/data_test_target.npy\"\n",
    "\n",
    "    train_X = train_Y = None\n",
    "    dev_X = dev_Y = None\n",
    "    test_X = test_Y = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.hop_length = 512\n",
    "\n",
    "        self.timeseries_length_list = []\n",
    "       # self.trainfiles_list = self.path_to_audiofiles(self.dir_trainfolder)\n",
    "       # self.devfiles_list = self.path_to_audiofiles(self.dir_devfolder)\n",
    "       # self.testfiles_list = self.path_to_audiofiles(self.dir_testfolder)\n",
    "\n",
    "        self.all_files_list = []\n",
    "\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_blues))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_classical))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_country))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_disco))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_hiphop))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_jazz))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_metal))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_pop))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_reggae))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_rock))\n",
    "\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_bamileke))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_bikutsi))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_makossa))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_salsa))\n",
    "        self.all_files_list.extend(self.path_to_audiofiles(self.dir_zouk))\n",
    "\n",
    "        shuffle(self.all_files_list)\n",
    "\n",
    "        self.trainfiles_list, self.testfiles_list, self.trainfiles_list, self.testfiles_list = train_test_split(self.all_files_list, self.all_files_list, test_size=0.2, random_state=1)\n",
    "        self.trainfiles_list, self.devfiles_list, self.trainfiles_list, self.devfiles_list = train_test_split(self.trainfiles_list, self.trainfiles_list, test_size=0.25, random_state=1)\n",
    "\n",
    "        \n",
    "        self.all_files_list = []\n",
    "        \n",
    "        \n",
    "        self.all_files_list.extend(self.trainfiles_list)\n",
    "        self.all_files_list.extend(self.devfiles_list)\n",
    "        self.all_files_list.extend(self.testfiles_list)\n",
    "    \n",
    "        self.timeseries_length = (\n",
    "            128\n",
    "        )   # sequence length == 128, default fftsize == 2048 & hop == 512 @ SR of 22050\n",
    "        #  equals 128 overlapped windows that cover approx ~3.065 seconds of audio, which is a bit small!\n",
    "\n",
    "    def load_preprocess_data(self):\n",
    "        print(\"[DEBUG] total number of files: \" + str(len(self.timeseries_length_list)))\n",
    "\n",
    "        # Training set\n",
    "        self.train_X, self.train_Y = self.extract_audio_features(self.trainfiles_list)\n",
    "        \n",
    "        print(\"\\nTRAIN_X array:\\n\")\n",
    "        print(self.train_X)\n",
    "        \n",
    "        print(\"\\nTRAIN_Y array:\\n\")\n",
    "        print(self.train_Y)\n",
    "        \n",
    "        \n",
    "        with open(self.train_X_preprocessed_data, \"wb\") as f:\n",
    "            np.save(f, self.train_X)\n",
    "            \n",
    "        with open(self.train_Y_preprocessed_data, \"wb\") as f:\n",
    "            self.train_Y = self.one_hot(self.train_Y)\n",
    "            np.save(f, self.train_Y)\n",
    "\n",
    "        # Validation set\n",
    "        self.dev_X, self.dev_Y = self.extract_audio_features(self.devfiles_list)\n",
    "        with open(self.dev_X_preprocessed_data, \"wb\") as f:\n",
    "            np.save(f, self.dev_X)\n",
    "        with open(self.dev_Y_preprocessed_data, \"wb\") as f:\n",
    "            self.dev_Y = self.one_hot(self.dev_Y)\n",
    "            np.save(f, self.dev_Y)\n",
    "\n",
    "        # Test set\n",
    "        self.test_X, self.test_Y = self.extract_audio_features(self.testfiles_list)\n",
    "        with open(self.test_X_preprocessed_data, \"wb\") as f:\n",
    "            np.save(f, self.test_X)\n",
    "        with open(self.test_Y_preprocessed_data, \"wb\") as f:\n",
    "            self.test_Y = self.one_hot(self.test_Y)\n",
    "            np.save(f, self.test_Y)\n",
    "\n",
    "    def load_deserialize_data(self):\n",
    "\n",
    "        self.train_X = np.load(self.train_X_preprocessed_data)\n",
    "        self.train_Y = np.load(self.train_Y_preprocessed_data)\n",
    "\n",
    "        self.dev_X = np.load(self.dev_X_preprocessed_data)\n",
    "        self.dev_Y = np.load(self.dev_Y_preprocessed_data)\n",
    "\n",
    "        self.test_X = np.load(self.test_X_preprocessed_data)\n",
    "        self.test_Y = np.load(self.test_Y_preprocessed_data)\n",
    "\n",
    "    def precompute_min_timeseries_len(self):\n",
    "        for file in self.all_files_list:\n",
    "            print(\"Loading \" + str(file))\n",
    "            y, sr = librosa.load(file)\n",
    "            self.timeseries_length_list.append(math.ceil(len(y) / self.hop_length))\n",
    "\n",
    "    def extract_audio_features(self, list_of_audiofiles):\n",
    "        \n",
    "        print(list_of_audiofiles)\n",
    "\n",
    "        data = np.zeros(\n",
    "            (len(list_of_audiofiles), self.timeseries_length, 33), dtype=np.float64\n",
    "        )\n",
    "        \n",
    "        target = []\n",
    "\n",
    "        for i, file in enumerate(list_of_audiofiles):\n",
    "            print(file)\n",
    "            \n",
    "            y, sr = librosa.load(file)\n",
    "            \n",
    "            #MFCC selection\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=y, sr=sr, hop_length=self.hop_length, n_mfcc=13\n",
    "            )\n",
    "            \n",
    "            #SPECTRAL_CENTER selection\n",
    "            spectral_center = librosa.feature.spectral_centroid(\n",
    "                y=y, sr=sr, hop_length=self.hop_length\n",
    "            )\n",
    "            \n",
    "            #CHROMA selection\n",
    "            chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=self.hop_length)\n",
    "            \n",
    "            #SPECTRAL CONTRAST selection\n",
    "            spectral_contrast = librosa.feature.spectral_contrast(\n",
    "                y=y, sr=sr, hop_length=self.hop_length\n",
    "            )\n",
    "\n",
    "            splits = re.split(\"[ .]\", file)\n",
    "            print(splits)\n",
    "            genre = re.split(\"[ /]\", splits[1])[4]\n",
    "            print(genre)\n",
    "            target.append(genre)\n",
    "\n",
    "            # MFCC Extraction\n",
    "            data[i, :, 0:13] = mfcc.T[0:self.timeseries_length, :]\n",
    "            \n",
    "            #SPECTRAL_CENTER Extraction\n",
    "            data[i, :, 13:14] = spectral_center.T[0:self.timeseries_length, :]\n",
    "            \n",
    "            #CHROMA Extraction\n",
    "            data[i, :, 14:26] = chroma.T[0:self.timeseries_length, :]\n",
    "            \n",
    "            #SPECTRAL_CONTRAST Extraction\n",
    "            data[i, :, 26:33] = spectral_contrast.T[0:self.timeseries_length, :]\n",
    "\n",
    "            print(\n",
    "                \"Extracted features audio track %i of %i.\"\n",
    "                % (i + 1, len(list_of_audiofiles))\n",
    "            )\n",
    "\n",
    "        return data, np.expand_dims(np.asarray(target), axis=1)\n",
    "\n",
    "    # ONE HOT ENCODING\n",
    "    def one_hot(self, Y_genre_strings):\n",
    "        y_one_hot = np.zeros((Y_genre_strings.shape[0], len(self.genre_list)))\n",
    "        for i, genre_string in enumerate(Y_genre_strings):\n",
    "            print(genre_string)\n",
    "            index = self.genre_list.index(genre_string)\n",
    "            y_one_hot[i, index] = 1\n",
    "        return y_one_hot\n",
    "\n",
    "    @staticmethod\n",
    "    def path_to_audiofiles(dir_folder):\n",
    "        list_of_audio = []\n",
    "        for file in os.listdir(dir_folder):\n",
    "            if file.endswith(\".au\") or file.endswith(\".wav\"):\n",
    "                directory = \"%s/%s\" % (dir_folder, file)\n",
    "                list_of_audio.append(directory)\n",
    "        return list_of_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logging level\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed files exist, deserializing npy files\n",
      "Training X shape: (900, 128, 33)\n",
      "Training Y shape: (900, 15)\n",
      "Dev X shape: (300, 128, 33)\n",
      "Dev Y shape: (300, 15)\n",
      "Test X shape: (300, 128, 33)\n",
      "Test Y shape: (300, 15)\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#\n",
    "# Check on pre-processed files. It generates those files and if they already exists use them.\n",
    "#\n",
    "########################################################\n",
    "genre_features = FeaturesExtraction()\n",
    "\n",
    "if (\n",
    "    os.path.isfile(genre_features.train_X_preprocessed_data)\n",
    "    and os.path.isfile(genre_features.train_Y_preprocessed_data)\n",
    "    and os.path.isfile(genre_features.dev_X_preprocessed_data)\n",
    "    and os.path.isfile(genre_features.dev_Y_preprocessed_data)\n",
    "    and os.path.isfile(genre_features.test_X_preprocessed_data)\n",
    "    and os.path.isfile(genre_features.test_Y_preprocessed_data)\n",
    "):\n",
    "    print(\"Preprocessed files exist, deserializing npy files\")\n",
    "    genre_features.load_deserialize_data()\n",
    "else:\n",
    "    print(\"Preprocessing raw audio files\")\n",
    "    genre_features.load_preprocess_data()\n",
    "\n",
    "print(\"Training X shape: \" + str(genre_features.train_X.shape))\n",
    "print(\"Training Y shape: \" + str(genre_features.train_Y.shape))\n",
    "print(\"Dev X shape: \" + str(genre_features.dev_X.shape))\n",
    "print(\"Dev Y shape: \" + str(genre_features.dev_Y.shape))\n",
    "print(\"Test X shape: \" + str(genre_features.test_X.shape))\n",
    "print(\"Test Y shape: \" + str(genre_features.test_Y.shape))\n",
    "\n",
    "input_shape = (genre_features.train_X.shape[1], genre_features.train_X.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM RNN model ...\n",
      "Compiling model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 128)          82944     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                495       \n",
      "=================================================================\n",
      "Total params: 104,047\n",
      "Trainable params: 104,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#\n",
    "# Long short-term memory RNN using Adam optimization\n",
    "#\n",
    "########################################################\n",
    "\n",
    "print(\"Build LSTM RNN model ...\")\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=128, dropout=0.05, recurrent_dropout=0.35, return_sequences=True, input_shape=input_shape))\n",
    "model.add(LSTM(units=32,  dropout=0.05, recurrent_dropout=0.35, return_sequences=False))\n",
    "model.add(Dense(units=genre_features.train_Y.shape[1], activation=\"softmax\"))\n",
    "\n",
    "print(\"Compiling model\")\n",
    "opt = Adam()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch 1/500\n",
      "900/900 [==============================] - 29s 33ms/step - loss: 2.6893 - accuracy: 0.0878\n",
      "Epoch 2/500\n",
      "900/900 [==============================] - 28s 32ms/step - loss: 2.5455 - accuracy: 0.1600\n",
      "Epoch 3/500\n",
      "900/900 [==============================] - 26s 29ms/step - loss: 2.4583 - accuracy: 0.1756\n",
      "Epoch 4/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.4294 - accuracy: 0.1811\n",
      "Epoch 5/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.4670 - accuracy: 0.1689\n",
      "Epoch 6/500\n",
      "900/900 [==============================] - 20s 23ms/step - loss: 2.3907 - accuracy: 0.1922\n",
      "Epoch 7/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.3407 - accuracy: 0.1956\n",
      "Epoch 8/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 2.3152 - accuracy: 0.2000\n",
      "Epoch 9/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 2.2841 - accuracy: 0.2111\n",
      "Epoch 10/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 2.2400 - accuracy: 0.2456\n",
      "Epoch 11/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 2.2201 - accuracy: 0.2300\n",
      "Epoch 12/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 2.1928 - accuracy: 0.2411\n",
      "Epoch 13/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.1633 - accuracy: 0.2578\n",
      "Epoch 14/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.1943 - accuracy: 0.2444\n",
      "Epoch 15/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.1252 - accuracy: 0.2511\n",
      "Epoch 16/500\n",
      "900/900 [==============================] - 21s 23ms/step - loss: 2.1030 - accuracy: 0.2756\n",
      "Epoch 17/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.1296 - accuracy: 0.2600\n",
      "Epoch 18/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 2.0790 - accuracy: 0.2667\n",
      "Epoch 19/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 2.1303 - accuracy: 0.2600\n",
      "Epoch 20/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 2.0612 - accuracy: 0.2933\n",
      "Epoch 21/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 2.0298 - accuracy: 0.2767\n",
      "Epoch 22/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 2.0511 - accuracy: 0.2911\n",
      "Epoch 23/500\n",
      "900/900 [==============================] - 18s 19ms/step - loss: 2.0192 - accuracy: 0.2811\n",
      "Epoch 24/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 2.0001 - accuracy: 0.2956\n",
      "Epoch 25/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 2.0068 - accuracy: 0.2967\n",
      "Epoch 26/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.9826 - accuracy: 0.3056\n",
      "Epoch 27/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.9806 - accuracy: 0.3100\n",
      "Epoch 28/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.9853 - accuracy: 0.2989\n",
      "Epoch 29/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 2.0027 - accuracy: 0.3056\n",
      "Epoch 30/500\n",
      "900/900 [==============================] - 21s 23ms/step - loss: 1.9450 - accuracy: 0.2989\n",
      "Epoch 31/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.9867 - accuracy: 0.2867\n",
      "Epoch 32/500\n",
      "900/900 [==============================] - 21s 23ms/step - loss: 1.9198 - accuracy: 0.3078\n",
      "Epoch 33/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.8904 - accuracy: 0.3300\n",
      "Epoch 34/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.8834 - accuracy: 0.3311\n",
      "Epoch 35/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.8705 - accuracy: 0.3500\n",
      "Epoch 36/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.8384 - accuracy: 0.3533\n",
      "Epoch 37/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.8905 - accuracy: 0.3300\n",
      "Epoch 38/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.8488 - accuracy: 0.3378\n",
      "Epoch 39/500\n",
      "900/900 [==============================] - 15s 17ms/step - loss: 1.8277 - accuracy: 0.3622\n",
      "Epoch 40/500\n",
      "900/900 [==============================] - 15s 17ms/step - loss: 1.8143 - accuracy: 0.3533\n",
      "Epoch 41/500\n",
      "900/900 [==============================] - 15s 17ms/step - loss: 1.8518 - accuracy: 0.3433\n",
      "Epoch 42/500\n",
      "900/900 [==============================] - 15s 17ms/step - loss: 1.8501 - accuracy: 0.3556\n",
      "Epoch 43/500\n",
      "900/900 [==============================] - 15s 17ms/step - loss: 1.8815 - accuracy: 0.3278\n",
      "Epoch 44/500\n",
      "900/900 [==============================] - 16s 17ms/step - loss: 1.8249 - accuracy: 0.3689\n",
      "Epoch 45/500\n",
      "900/900 [==============================] - 15s 17ms/step - loss: 1.8001 - accuracy: 0.3678\n",
      "Epoch 46/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.7831 - accuracy: 0.3578\n",
      "Epoch 47/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.7483 - accuracy: 0.3767\n",
      "Epoch 48/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.7404 - accuracy: 0.4078\n",
      "Epoch 49/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.7462 - accuracy: 0.3789\n",
      "Epoch 50/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.7221 - accuracy: 0.4011\n",
      "Epoch 51/500\n",
      "900/900 [==============================] - 19s 22ms/step - loss: 1.6926 - accuracy: 0.4189\n",
      "Epoch 52/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.7000 - accuracy: 0.4100\n",
      "Epoch 53/500\n",
      "900/900 [==============================] - 17s 18ms/step - loss: 1.6246 - accuracy: 0.4089\n",
      "Epoch 54/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.6860 - accuracy: 0.4222\n",
      "Epoch 55/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.7275 - accuracy: 0.4011\n",
      "Epoch 56/500\n",
      "900/900 [==============================] - 17s 18ms/step - loss: 1.6771 - accuracy: 0.4178\n",
      "Epoch 57/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.6265 - accuracy: 0.4400\n",
      "Epoch 58/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.6061 - accuracy: 0.4267\n",
      "Epoch 59/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5642 - accuracy: 0.4433\n",
      "Epoch 60/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5634 - accuracy: 0.4567\n",
      "Epoch 61/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5634 - accuracy: 0.4544\n",
      "Epoch 62/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5496 - accuracy: 0.4656\n",
      "Epoch 63/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.5689 - accuracy: 0.4411\n",
      "Epoch 64/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.5269 - accuracy: 0.4733\n",
      "Epoch 65/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.4974 - accuracy: 0.4722\n",
      "Epoch 66/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.5508 - accuracy: 0.4689\n",
      "Epoch 67/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.5845 - accuracy: 0.4400\n",
      "Epoch 68/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.4970 - accuracy: 0.4867\n",
      "Epoch 69/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.4449 - accuracy: 0.4944\n",
      "Epoch 70/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5383 - accuracy: 0.4356\n",
      "Epoch 71/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5482 - accuracy: 0.4478\n",
      "Epoch 72/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.4040 - accuracy: 0.5133\n",
      "Epoch 73/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.5029 - accuracy: 0.4778\n",
      "Epoch 74/500\n",
      "900/900 [==============================] - 17s 18ms/step - loss: 1.4624 - accuracy: 0.4911\n",
      "Epoch 75/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.4720 - accuracy: 0.5044\n",
      "Epoch 76/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.4596 - accuracy: 0.4956\n",
      "Epoch 77/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.4063 - accuracy: 0.5178\n",
      "Epoch 78/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.4068 - accuracy: 0.5367\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 18s 20ms/step - loss: 1.4173 - accuracy: 0.5022\n",
      "Epoch 80/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.3830 - accuracy: 0.5133\n",
      "Epoch 81/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.3601 - accuracy: 0.5344\n",
      "Epoch 82/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.3422 - accuracy: 0.5511\n",
      "Epoch 83/500\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 1.2997 - accuracy: 0.5489\n",
      "Epoch 84/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.3101 - accuracy: 0.5367\n",
      "Epoch 85/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.3248 - accuracy: 0.5411\n",
      "Epoch 86/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.3219 - accuracy: 0.5411\n",
      "Epoch 87/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.3212 - accuracy: 0.5500\n",
      "Epoch 88/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.2671 - accuracy: 0.5522\n",
      "Epoch 89/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.3336 - accuracy: 0.5311\n",
      "Epoch 90/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.3515 - accuracy: 0.5422\n",
      "Epoch 91/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2883 - accuracy: 0.5667\n",
      "Epoch 92/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2827 - accuracy: 0.5544\n",
      "Epoch 93/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2639 - accuracy: 0.5500\n",
      "Epoch 94/500\n",
      "900/900 [==============================] - 17s 18ms/step - loss: 1.2736 - accuracy: 0.5456\n",
      "Epoch 95/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2471 - accuracy: 0.5700\n",
      "Epoch 96/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2542 - accuracy: 0.5778\n",
      "Epoch 97/500\n",
      "900/900 [==============================] - 17s 18ms/step - loss: 1.2920 - accuracy: 0.5478\n",
      "Epoch 98/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2076 - accuracy: 0.5811\n",
      "Epoch 99/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.2489 - accuracy: 0.5611\n",
      "Epoch 100/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.2546 - accuracy: 0.5644\n",
      "Epoch 101/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.2585 - accuracy: 0.5578\n",
      "Epoch 102/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.2821 - accuracy: 0.5456\n",
      "Epoch 103/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.2657 - accuracy: 0.5622\n",
      "Epoch 104/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2692 - accuracy: 0.5622\n",
      "Epoch 105/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2401 - accuracy: 0.5656\n",
      "Epoch 106/500\n",
      "900/900 [==============================] - 17s 18ms/step - loss: 1.2257 - accuracy: 0.5856\n",
      "Epoch 107/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1939 - accuracy: 0.5922\n",
      "Epoch 108/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.2007 - accuracy: 0.5800\n",
      "Epoch 109/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1928 - accuracy: 0.5833\n",
      "Epoch 110/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.2455 - accuracy: 0.5711\n",
      "Epoch 111/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1964 - accuracy: 0.5900\n",
      "Epoch 112/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.1951 - accuracy: 0.5889\n",
      "Epoch 113/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1767 - accuracy: 0.6056\n",
      "Epoch 114/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1974 - accuracy: 0.5800\n",
      "Epoch 115/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.1605 - accuracy: 0.5944\n",
      "Epoch 116/500\n",
      "900/900 [==============================] - 19s 22ms/step - loss: 1.2052 - accuracy: 0.5878\n",
      "Epoch 117/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.1586 - accuracy: 0.5967\n",
      "Epoch 118/500\n",
      "900/900 [==============================] - 19s 22ms/step - loss: 1.2473 - accuracy: 0.5711\n",
      "Epoch 119/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.1212 - accuracy: 0.6089\n",
      "Epoch 120/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1584 - accuracy: 0.6011\n",
      "Epoch 121/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1900 - accuracy: 0.5856\n",
      "Epoch 122/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1533 - accuracy: 0.6033\n",
      "Epoch 123/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1599 - accuracy: 0.6067\n",
      "Epoch 124/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1774 - accuracy: 0.5844\n",
      "Epoch 125/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1945 - accuracy: 0.5811\n",
      "Epoch 126/500\n",
      "900/900 [==============================] - 18s 19ms/step - loss: 1.1424 - accuracy: 0.6111\n",
      "Epoch 127/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1616 - accuracy: 0.6067\n",
      "Epoch 128/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1257 - accuracy: 0.5944\n",
      "Epoch 129/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1154 - accuracy: 0.6078\n",
      "Epoch 130/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1787 - accuracy: 0.5889\n",
      "Epoch 131/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0978 - accuracy: 0.6167\n",
      "Epoch 132/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1288 - accuracy: 0.6233\n",
      "Epoch 133/500\n",
      "900/900 [==============================] - 20s 23ms/step - loss: 1.1614 - accuracy: 0.6000\n",
      "Epoch 134/500\n",
      "900/900 [==============================] - 19s 22ms/step - loss: 1.1045 - accuracy: 0.5911\n",
      "Epoch 135/500\n",
      "900/900 [==============================] - 20s 23ms/step - loss: 1.1070 - accuracy: 0.6178\n",
      "Epoch 136/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.1489 - accuracy: 0.5800\n",
      "Epoch 137/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.0959 - accuracy: 0.6167\n",
      "Epoch 138/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.0988 - accuracy: 0.6356\n",
      "Epoch 139/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1277 - accuracy: 0.6044\n",
      "Epoch 140/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.0964 - accuracy: 0.6144\n",
      "Epoch 141/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0916 - accuracy: 0.6100\n",
      "Epoch 142/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.0732 - accuracy: 0.6233\n",
      "Epoch 143/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0845 - accuracy: 0.6100\n",
      "Epoch 144/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0711 - accuracy: 0.6289\n",
      "Epoch 145/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.1404 - accuracy: 0.6144\n",
      "Epoch 146/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0704 - accuracy: 0.6222\n",
      "Epoch 147/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.0375 - accuracy: 0.6511\n",
      "Epoch 148/500\n",
      "900/900 [==============================] - 18s 19ms/step - loss: 1.0286 - accuracy: 0.6356\n",
      "Epoch 149/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1042 - accuracy: 0.6156\n",
      "Epoch 150/500\n",
      "900/900 [==============================] - 22s 25ms/step - loss: 1.1556 - accuracy: 0.5989\n",
      "Epoch 151/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.1000 - accuracy: 0.6200\n",
      "Epoch 152/500\n",
      "900/900 [==============================] - 19s 22ms/step - loss: 1.0239 - accuracy: 0.6400\n",
      "Epoch 153/500\n",
      "900/900 [==============================] - 18s 21ms/step - loss: 1.0961 - accuracy: 0.6144\n",
      "Epoch 154/500\n",
      "900/900 [==============================] - 19s 21ms/step - loss: 1.0642 - accuracy: 0.6078\n",
      "Epoch 155/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.1037 - accuracy: 0.6133\n",
      "Epoch 156/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0414 - accuracy: 0.6478\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0632 - accuracy: 0.6300\n",
      "Epoch 158/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0558 - accuracy: 0.6389\n",
      "Epoch 159/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.0598 - accuracy: 0.6222\n",
      "Epoch 160/500\n",
      "900/900 [==============================] - 17s 19ms/step - loss: 1.0482 - accuracy: 0.6411\n",
      "Epoch 161/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.0188 - accuracy: 0.6433\n",
      "Epoch 162/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.0421 - accuracy: 0.6411\n",
      "Epoch 163/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 0.9944 - accuracy: 0.6411\n",
      "Epoch 164/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.0385 - accuracy: 0.6567\n",
      "Epoch 165/500\n",
      "900/900 [==============================] - 16s 18ms/step - loss: 1.0117 - accuracy: 0.6500\n",
      "Epoch 166/500\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 1.0568 - accuracy: 0.6244\n",
      "Epoch 167/500\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 0.9905 - accuracy: 0.6500\n",
      "Epoch 168/500\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 0.9902 - accuracy: 0.6611\n",
      "Epoch 169/500\n",
      "900/900 [==============================] - 42s 47ms/step - loss: 1.0299 - accuracy: 0.6400\n",
      "Epoch 170/500\n",
      "900/900 [==============================] - 36s 40ms/step - loss: 1.0302 - accuracy: 0.6378\n",
      "Epoch 171/500\n",
      "900/900 [==============================] - 36s 40ms/step - loss: 1.0651 - accuracy: 0.6256\n",
      "Epoch 172/500\n",
      "900/900 [==============================] - 27s 30ms/step - loss: 0.9545 - accuracy: 0.6733\n",
      "Epoch 173/500\n",
      "900/900 [==============================] - 25s 28ms/step - loss: 1.0465 - accuracy: 0.6311\n",
      "Epoch 174/500\n",
      "900/900 [==============================] - 20s 22ms/step - loss: 1.0561 - accuracy: 0.6267\n",
      "Epoch 175/500\n",
      "900/900 [==============================] - 28s 32ms/step - loss: 1.0006 - accuracy: 0.6622\n",
      "Epoch 176/500\n",
      "900/900 [==============================] - 35s 39ms/step - loss: 0.9377 - accuracy: 0.6767\n",
      "Epoch 177/500\n",
      "900/900 [==============================] - 77s 86ms/step - loss: 0.9536 - accuracy: 0.6544\n",
      "Epoch 178/500\n",
      "900/900 [==============================] - 64s 71ms/step - loss: 0.9853 - accuracy: 0.6544\n",
      "Epoch 179/500\n",
      "900/900 [==============================] - 47s 53ms/step - loss: 0.9812 - accuracy: 0.6611\n",
      "Epoch 180/500\n",
      "900/900 [==============================] - 42s 47ms/step - loss: 0.9848 - accuracy: 0.6600\n",
      "Epoch 181/500\n",
      "900/900 [==============================] - 47s 52ms/step - loss: 0.9646 - accuracy: 0.6722\n",
      "Epoch 182/500\n",
      "900/900 [==============================] - 41s 46ms/step - loss: 0.9496 - accuracy: 0.6756\n",
      "Epoch 183/500\n",
      "900/900 [==============================] - 50s 55ms/step - loss: 1.0205 - accuracy: 0.6567\n",
      "Epoch 184/500\n",
      "900/900 [==============================] - 53s 59ms/step - loss: 1.0024 - accuracy: 0.6400\n",
      "Epoch 185/500\n",
      "900/900 [==============================] - 144s 160ms/step - loss: 0.9550 - accuracy: 0.6756\n",
      "Epoch 186/500\n",
      "900/900 [==============================] - 238s 264ms/step - loss: 1.0215 - accuracy: 0.6367\n",
      "Epoch 187/500\n",
      "900/900 [==============================] - 112s 124ms/step - loss: 0.9782 - accuracy: 0.6500\n",
      "Epoch 188/500\n",
      "900/900 [==============================] - 208s 231ms/step - loss: 0.9183 - accuracy: 0.6722\n",
      "Epoch 189/500\n",
      "900/900 [==============================] - 219s 244ms/step - loss: 1.0130 - accuracy: 0.6433\n",
      "Epoch 190/500\n",
      "430/900 [=============>................] - ETA: 58s - loss: 0.9300 - accuracy: 0.6721"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "#\n",
    "# Training\n",
    "# Batch size = 35\n",
    "# Epochs = 400\n",
    "#\n",
    "########################################################\n",
    "\n",
    "print(\"Training ...\")\n",
    "batch_size = 10\n",
    "num_epochs = 500\n",
    "model.fit(\n",
    "    genre_features.train_X,\n",
    "    genre_features.train_Y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#\n",
    "# Validation\n",
    "#\n",
    "########################################################\n",
    "\n",
    "print(\"Validating ...\")\n",
    "score, accuracy = model.evaluate(\n",
    "    genre_features.dev_X, genre_features.dev_Y, batch_size=batch_size, verbose=1\n",
    ")\n",
    "print(\"Dev loss:  \", score)\n",
    "print(\"Dev accuracy:  \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#\n",
    "# Testing\n",
    "#\n",
    "########################################################\n",
    "\n",
    "print(\"Testing ...\")\n",
    "score, accuracy = model.evaluate(\n",
    "    genre_features.test_X, genre_features.test_Y, batch_size=batch_size, verbose=1\n",
    ")\n",
    "print(\"Test loss:  \", score)\n",
    "print(\"Test accuracy:  \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#\n",
    "# Store HDF5 file model\n",
    "#\n",
    "########################################################\n",
    "\n",
    "model_filename = \"lstm_genre_classifier_lstm.h5\"\n",
    "print(\"Saving model: \" + model_filename)\n",
    "model.save(model_filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#\n",
    "# Prediction test\n",
    "#\n",
    "########################################################\n",
    "import sys\n",
    "\n",
    "def load_model(model_path, weights_path):\n",
    "    \"Load the trained LSTM model from directory for genre classification\"\n",
    "    with open(model_path, \"r\") as model_file:\n",
    "        trained_model = model_from_json(model_file.read())\n",
    "    trained_model.load_weights(weights_path)\n",
    "    trained_model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def extract_audio_features(file):\n",
    "    \"Extract audio features from an audio file for genre classification\"\n",
    "    timeseries_length = 128\n",
    "    features = np.zeros((1, timeseries_length, 33), dtype=np.float64)\n",
    "\n",
    "    y, sr = librosa.load(file)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=512, n_mfcc=13)\n",
    "    spectral_center = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=512)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=512)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr, hop_length=512)\n",
    "\n",
    "    features[0, :, 0:13] = mfcc.T[0:timeseries_length, :]\n",
    "    features[0, :, 13:14] = spectral_center.T[0:timeseries_length, :]\n",
    "    features[0, :, 14:26] = chroma.T[0:timeseries_length, :]\n",
    "    features[0, :, 26:33] = spectral_contrast.T[0:timeseries_length, :]\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_genre(model, music_path):\n",
    "    \"Predict genre of music using a trained model\"\n",
    "    prediction = model.predict(extract_audio_features(music_path))\n",
    "    predict_genre = FeaturesExtraction().genre_list[np.argmax(prediction)]\n",
    "    return predict_genre\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #PATH = sys.argv[1] if len(sys.argv) == 2 else \"./audio/classical_music.mp3\"\n",
    "    PATH = \"./audio/\"\n",
    "    f = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(PATH):\n",
    "        f.extend(filenames)\n",
    "        break\n",
    "    \n",
    "    for f in filenames:\n",
    "        print(\"Trying to predict the genre of \"+f)\n",
    "        GENRE = get_genre(model, PATH+f)\n",
    "        print(\"Model predict: {}\".format(GENRE))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
